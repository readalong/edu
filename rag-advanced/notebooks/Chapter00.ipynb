{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xnai8-wEsdO"
      },
      "source": [
        "## Chapter 0: Setup\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/wandb/edu/blob/main/rag-advanced/notebooks/Chapter00.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "<!--- @wandbcode{rag-course-00} -->\n",
        "\n",
        "Let's install the required packages and check our setup for this course.\n",
        "\n",
        "###  Free Cohere API key\n",
        "\n",
        "Before you run this colab notebook, head over to this [link to redeem a free Cohere API key](https://docs.google.com/forms/d/e/1FAIpQLSc9x4nV8_nSQvJnaINO1j9NIa2IUbAJqrKeSllNNCCbMFmCxw/viewform?usp=sf_link).\n",
        "\n",
        "Alternatively if you have a Cohere API key feel free to proceed. :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZ3-dK6aEsdR",
        "outputId": "f9838576-da04-49f8-f315-8f991a2873f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/353.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m353.2/353.2 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/252.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m252.5/252.5 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/590.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/3.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m\u001b[0m\u001b[91m\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m114.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/325.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m325.8/325.8 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/203.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/74.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qq weave cohere"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wastpaCIEsdT"
      },
      "source": [
        "## 1. Setup Weave\n",
        "\n",
        "\n",
        "The code cell below will prompt you to put in a W&B API key. You can get your API key by heading over to https://wandb.ai/authorize."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "SrwctlCVEsdT",
        "outputId": "834fd5cb-06da-433c-a8a5-63b7f8567e75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please login to Weights & Biases (https://wandb.ai/) to continue:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logged in as Weights & Biases user: rastogi-vishu.\n",
            "View Weave data at https://wandb.ai/rastogi-vishu-home/rag-course/weave\n"
          ]
        }
      ],
      "source": [
        "# import weave\n",
        "import weave\n",
        "\n",
        "# initialize weave client\n",
        "weave_client = weave.init(\"rag-course\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxNJ3gykEsdT"
      },
      "source": [
        "## 2. Setup Cohere\n",
        "\n",
        "The code cell below will prompt you to put in a Cohere API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gx8VEgoEsdU",
        "outputId": "98bebd1b-4304-4faa-b44c-9f93197eb6c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter your COHERE_API_KEY路路路路路路路路路路\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "\n",
        "import cohere\n",
        "\n",
        "cohere_client = cohere.ClientV2(\n",
        "    api_key=getpass.getpass(\"Please enter your COHERE_API_KEY\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XcjEUAJEsdU"
      },
      "source": [
        "## A simple-turn chat with Cohere's command-r-plus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjXYRVqSEsdU",
        "outputId": "edae84f4-40bf-4272-bda6-92ce8da32344"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " https://wandb.ai/rastogi-vishu-home/rag-course/r/call/01949c25-2bc4-72b2-baee-aa07cdc5c990\n",
            "id='f84c5a65-7a5c-4b33-afcf-cf326aa49d78' finish_reason='COMPLETE' prompt=None message=AssistantMessageResponse(role='assistant', tool_calls=None, tool_plan=None, content=[TextAssistantMessageResponseContentItem(type='text', text=\"Retrieval-Augmented Generation (RAG) is a natural language processing (NLP) technique that combines information retrieval with language generation. It aims to enhance the quality and factual accuracy of generated text by retrieving relevant information from an external source of knowledge, such as a large corpus of text documents or a structured knowledge base.\\n\\nHere's a simplified breakdown of how RAG works:\\n\\n1. **Information Retrieval**: RAG starts by taking a natural language input, such as a question or a prompt. It then uses information retrieval techniques, often based on dense vector representations, to search through a knowledge source and retrieve relevant pieces of information. This knowledge source can be a collection of documents, web pages, or any structured or unstructured text data.\\n\\n2. **Generation**: Once the relevant information is retrieved, a language generation model, typically based on transformer architectures like BERT or GPT, takes both the input and the retrieved context as input. The model then generates a response, such as an answer to a question or a continuation of a text prompt. The generation process is informed by the retrieved context, allowing the model to incorporate factual information into its output.\\n\\n3. **Training**: RAG models are typically trained using a combination of language modeling objectives and supervised objectives. They learn to generate coherent and contextually appropriate responses while also being rewarded for selecting relevant information from the knowledge source. This training process helps the model develop a better understanding of the relationship between the input, the retrieved context, and the desired output.\\n\\nThe key advantage of RAG is that it mitigates the hallucination problem often seen in language models, where they generate factually incorrect or inconsistent responses. By grounding the generation process in external knowledge, RAG improves the accuracy and faithfulness of the generated text.\\n\\nRAG has been applied to various tasks, including question answering, dialogue generation, text completion, and summarization. It has shown promising results in generating more informative and factually consistent responses compared to language models that rely solely on their internal parameters without accessing external knowledge sources.\")], citations=None) usage=Usage(billed_units=UsageBilledUnits(input_tokens=9.0, output_tokens=415.0, search_units=None, classifications=None), tokens=UsageTokens(input_tokens=202.0, output_tokens=415.0)) logprobs=None\n"
          ]
        }
      ],
      "source": [
        "response = cohere_client.chat(\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"What is retrieval augmented generation (RAG)?\"}\n",
        "    ],\n",
        "    model=\"command-r-plus\",\n",
        "    temperature=0.1,\n",
        "    max_tokens=2000,\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_v92NP6aEsdU"
      },
      "source": [
        "Let's head over to the weave URL to check out the generated response."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}